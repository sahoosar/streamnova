# ============================================================================
# Application
# ============================================================================
spring:
  config:
    import: optional:classpath:sql-queries.yml
  application:
    name: StreamNova  # Used in logs and transaction events

  # Active profiles: set via --spring.profiles.active=postgres or env SPRING_PROFILES_ACTIVE=postgres,sit
  # (Spring Boot 3.5+ does not support spring.profiles in config; use CLI or env instead.)
  devtools:
    add-properties: false  # Disable property-defaults log message (optional)

  # Flyway: runs when a DataSource is configured (e.g. spring.datasource.url in a profile).
  # Migrations in classpath:db/migration/ create agent tables and dataflow_job_metadata (PostgreSQL).
  # To use: set spring.datasource.url (and username/password) to your Postgres DB; Flyway runs on startup.
  flyway:
    enabled: true
    locations: classpath:db/migration
    baseline-on-migrate: true

# Context path (e.g. when behind a proxy at /streamnova)
server:
  servlet:
    context-path: /streamnova

# ============================================================================
# Actuator - Metrics & Monitoring
# ============================================================================
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: when-authorized
    metrics:
      enabled: true
    prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    distribution:
      percentiles-histogram:
        http.server.requests: true
      sla:
        http.server.requests: 100ms,500ms,1s,2s,5s

# ============================================================================
# Logging
# ============================================================================
logging:
  level:
    root: INFO
    com.di.streamnova: INFO
    DLQ: INFO
    VALID: INFO
    # Optional: uncomment to see Spring's request mapping resolution (noisier)
    # org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping: TRACE
    # org.springframework.web.servlet.DispatcherServlet: DEBUG

# ============================================================================
# StreamNova - Guardrails
# ============================================================================
# Allowed machine types at recommend/execute. Comma-separated; exact or family prefix (e.g. n2 = n2-*).
# Empty = no restriction.
streamnova:
  # Request logging: log method, URI, and body to console (helps debug POST vs GET). Set enabled: false to disable.
  request-logging:
    enabled: true
    max-body-length: 2048

  # Project-level AspectJ transaction tracking: [TX-START] / [TX-END] / [TX-FAIL], metrics, and txId in MDC.
  # track-controllers: every REST controller method. track-services: runner + agent/config services.
  # metrics-enabled: publish streamnova.tx.duration and streamnova.tx.count to Micrometer (Prometheus).
  # structured-logging: log as key=value (event=TX-START layer=... ) for log aggregation (ELK, Splunk).
  # MDC tracing: every request gets requestId + requestPath (MdcRequestFilter); agent endpoints add caller_agent_id/execution_run_id; logback includes %X{...} for correlation in concurrent/multithreaded logs.
  aspect:
    track-controllers: true
    track-services: true
    metrics-enabled: true
    metric-name-prefix: streamnova.tx
    structured-logging: true

  # ============================================================================
  # GUARDRAILS MODULE
  # All guardrail values are YAML-only. No @Value annotation or hard-coded
  # list exists anywhere in the codebase — change here, redeploy, done.
  #
  # Per-environment overrides belong in application-{profile}.yml.
  # Per-request overrides (maxCostUsd, allowedMachineTypes query params) are
  # merged at runtime by GuardrailService.buildWithOverrides().
  # ============================================================================
  guardrails:

    # -- Machine-type allow-list -----------------------------------------------
    # Exact match OR family prefix (n2d matches all n2d-* types). Empty = no restriction.
    allowed-machine-types: n2d-standard-4,n2d-standard-8,n2d-standard-16,n2-standard-4,n2-standard-8,n2-standard-16,c3-standard-4,c3-standard-8,c3-standard-16

    # Ordered machine-family preference (keep n2d before n2).
    machine-family-order: n2d,n2,c3

    # -- Cost / duration / throughput limits (null = no limit) ----------------
    # Uncomment and set to activate. Override per profile in application-{env}.yml.
    # max-cost-usd:              # e.g. 5.00   — max estimated $ per run
    # max-duration-sec:          # e.g. 7200   — 2h max per run
    # min-throughput-mb-per-sec: # e.g. 10     — reject slow candidates

    # -- Worker / shard global caps -------------------------------------------
    max-workers-global: 0    # 0 = use recommend.max-workers-cap
    max-shards-global:  0    # 0 = derive from DB pool size

    # -- Concurrency (shared pool) --------------------------------------------
    # Max concurrent runs when not exclusive. 0 = no cap. E.g. 2 = at most 2 loads at a time (more 429s, shorter per-load time).
    max-concurrent-runs: 0

    # -- Enforcement switches (set false to disable without removing config) ---
    enforce-on-recommend: true
    enforce-on-execute:   true

  # --------------------------------------------------------------------------
  # Estimator (duration and cost estimation)
  # --------------------------------------------------------------------------
  estimator:
    usd-per-vcpu-hour:  # USD per vCPU-hour by family (override for region/pricing)
      n2: 0.031
      n2d: 0.027
      c3: 0.035
    machine-family-prefixes: n2d,n2,c3   # Ordered; first match wins (n2d before n2)
    machine-family-default: n2           # Default when no prefix matches
    usd-to-gbp: 0.79                     # Display rate for cost in GBP
    default-throughput-mb-per-sec: 50    # When no warm-up or history
    fallback-duration-sec: 3600           # When effective throughput is 0
    learning-signals-limit: 100           # Max past runs for duration/cost corrections
    throughput-history-limit: 10          # Max past runs for throughput history fallback
    source-cap:                           # MB/s by DB type
      postgres: 500
      oracle: 80
    sink-cap:                             # MB/s by load pattern (bq-direct / gcs-bq)
      bq-direct: 100
      gcs-bq: 400
    cpu-cap-mb-per-sec-per-vcpu: 60       # CPU cap = this × workers × vCPUs

  # --------------------------------------------------------------------------
  # Recommend API (profile → candidates → estimate → recommend)
  # --------------------------------------------------------------------------
  recommend:
    max-candidates: 4           # Lower = faster; higher = more options
    max-workers: 4              # Worker counts 1, 2, … up to this
    max-workers-cap: 8          # Safety: effective max = min(max-workers, this)
    fallback-pool-size: 4       # When pool not in config; match pipeline fallbackPoolSize
    max-concurrent-requests: 0  # 0 = no limit; else 429 when exceeded
    concurrent-request-acquire-timeout-sec: 5  # Wait for slot before 429

  # --------------------------------------------------------------------------
  # Execution planner (candidate generation)
  # --------------------------------------------------------------------------
  execution-planner:
    machine-ladder:
      # Order = evaluation order. Empty = built-in default (n2d, n2, c3)
      types:
        - n2d-standard-4
        - n2d-standard-8
        - n2d-standard-16
        - n2-standard-4
        - n2-standard-8
        - n2-standard-16
        - c3-standard-4
        - c3-standard-8
        - c3-standard-16

  # --------------------------------------------------------------------------
  # Shard planner
  # --------------------------------------------------------------------------
  shardplanner:
    max-shards-cap: 4                    # When pool not provided (e.g. tests)
    fallback-shards-when-no-vcpus: 4      # When vCPUs cannot be parsed
    high-cpu-target-records-per-shard: 20000
    high-mem-target-records-per-shard: 100000
    standard-target-records-per-shard: 50000
    fallback-max-records-per-shard: 200000  # Min-shards when size not available
    max-mb-per-shard: 256                   # Min-shards when size available (MB)
    pool-headroom-ratio: 0.8                # Shard cap = pool-size × this (e.g. 80%)

  # --------------------------------------------------------------------------
  # Adaptive fetch size (PostgresHandler: scale JDBC fetch size by table size)
  # --------------------------------------------------------------------------
  adaptive-fetch:
    # Row count above which "large dataset" rules apply: fetchSize = min(large-max, base * large-multiplier)
    large-dataset-threshold-rows: 10000000   # 10M
    large-dataset-max-fetch-size: 50000
    large-dataset-multiplier: 10
    # Row count above which "medium dataset" rules apply (below large threshold)
    medium-dataset-threshold-rows: 1000000  # 1M
    medium-dataset-max-fetch-size: 20000
    medium-dataset-multiplier: 4

  # --------------------------------------------------------------------------
  # Profiler (table stats and warm-up)
  # --------------------------------------------------------------------------
  profiler:
    warm-up-rows: 5000
    warm-up-fetch-size: 1000
    # Profile store cache: only used when metrics.persistence-enabled=true AND cache-enabled=true.
    # Lower/test: leave cache-enabled false (persistent store, no cache). Higher env: set true.
    cache-enabled: ${STREAMNOVA_PROFILE_CACHE_ENABLED:false}
    cache:
      by-run-id:
        max-size: ${STREAMNOVA_PROFILE_CACHE_BY_RUN_ID_MAX_SIZE:1000}
        expire-after-write-minutes: ${STREAMNOVA_PROFILE_CACHE_BY_RUN_ID_EXPIRE_MIN:30}
      recent-by-table:
        max-size: ${STREAMNOVA_PROFILE_CACHE_RECENT_MAX_SIZE:500}
        expire-after-write-minutes: ${STREAMNOVA_PROFILE_CACHE_RECENT_EXPIRE_MIN:5}

  # --------------------------------------------------------------------------
  # Capacity (execute admission and rate limiting)
  # --------------------------------------------------------------------------
  capacity:
    resource-limited-message: "Due to minimal resources, the request cannot be processed. Please retry later."
    retry-after-sec: 60
    max-shards: 0  # 0 = derive from pipeline_config maximumPoolSize; set >0 to override
    shards-not-available-message: "Not enough shards available; please wait for full availability."
    # Max concurrent execute attempts (POST execute + webhook execute). 0 = no limit.
    # When set, excess requests get 429 (handles request floods in shared-pool mode). Recommend setting when using shared pool (e.g. 10).
    max-concurrent-execute-requests: 0

  # --------------------------------------------------------------------------
  # Metrics & learning store (multi-agent tracking)
  # When true and a datasource is configured, execution status and estimates are persisted to agent_runs / agent_estimates_vs_actuals.
  # Each of the 10 agents should send caller_agent_id in the webhook body; use GET /api/agent/executions?callerAgentId=agent-1 to list their runs.
  # --------------------------------------------------------------------------
  metrics:
    persistence-enabled: ${STREAMNOVA_METRICS_PERSISTENCE_ENABLED:false}
    # Agent invocation audit (when persistence-enabled=true): max lengths for stored request/response summary and endpoint.
    audit:
      max-summary-length: ${STREAMNOVA_AUDIT_MAX_SUMMARY_LENGTH:4096}
      max-endpoint-length: ${STREAMNOVA_AUDIT_MAX_ENDPOINT_LENGTH:256}

  # --------------------------------------------------------------------------
  # Statistics / pipeline config
  # --------------------------------------------------------------------------
  statistics:
    # Input sources to support. Matches spring.profiles (postgres, oracle, or both).
    # When both: postgres and oracle pipeline configs are loaded and datasources created for each.
    #supported-source-types: postgres,oracle

  # --------------------------------------------------------------------------
  # Spring AI — Vertex AI (Gemini) configuration
  # Override per profile in application-{profile}.yml
  # --------------------------------------------------------------------------
  ai:
    enabled: ${STREAMNOVA_AI_ENABLED:true}
    # Vertex AI project + location (mirrors spring.ai.vertex.ai.gemini.* below)
    vertex:
      project-id: ${VERTEX_PROJECT_ID:your-gcp-project-id}
      location:   ${VERTEX_LOCATION:us-central1}
    # Gemini chat model defaults
    chat:
      model:            ${AI_CHAT_MODEL:gemini-2.0-flash-001}
      temperature:      ${AI_TEMPERATURE:0.3}
      top-p:            ${AI_TOP_P:0.95}
      max-output-tokens: ${AI_MAX_TOKENS:8192}
    # Embedding model
    embedding:
      model: ${AI_EMBEDDING_MODEL:text-embedding-004}
    # Agent behaviour
    agent:
      max-iterations:   ${AI_AGENT_MAX_ITERATIONS:10}
      timeout-seconds:  ${AI_AGENT_TIMEOUT_SECONDS:60}
      retry-attempts:   ${AI_AGENT_RETRY_ATTEMPTS:3}
      memory-enabled:   ${AI_AGENT_MEMORY_ENABLED:true}
      memory-max-turns: ${AI_AGENT_MEMORY_MAX_TURNS:20}

  # --------------------------------------------------------------------------
  # Pipeline config: event configs only (database_event_config.yml, gcs_event_config.yml, bq_event_config.yml)
  # --------------------------------------------------------------------------
  pipeline:
    # Use event configs per user choice (2-stage or 3-stage). Config loaded from database_event_config.yml (all DBs), gcs_event_config.yml, bq_event_config.yml.
    use-event-configs-only: true
    # Listener config (entrypoint for 2-stage / 3-stage). Override per env in application-{profile}.yml (e.g. pipeline_listener_config-sit.yml).
    listener-config-file: classpath:pipeline_listener_config.yml
    event-config-files:
      # Generic database config: one file for all JDBC sources (postgres, oracle, mysql, etc.)
      postgres: classpath:database_event_config.yml
      oracle: classpath:database_event_config.yml
      mysql: classpath:database_event_config.yml
      gcs: classpath:gcs_event_config.yml
      bigquery: classpath:bq_event_config.yml
      bq: classpath:bq_event_config.yml   # alias for bigquery
    # Default values for template context when event config (e.g. gcs_event_config destinations.gcs) does not set them.
    template-defaults:
      file-format: PARQUET    # PARQUET | AVRO | CSV | JSONL
      compression: SNAPPY
      # Target size per output file (MB). Optional: actual file sizes may vary. Use 0 to omit (runner default).
      target-file-size-mb: 64
      write-mode: APPEND      # APPEND | OVERWRITE
      trace-enabled: true
    # Template paths per workflow (source/target). Used for template-based execution and template-details endpoint.
    templates:
      db-to-gcs: classpath:pipeline-db-to-gcs-template.yml
      db-to-gcs-to-bq: classpath:pipeline-db-to-gcs-to-bq-template.yml
      gcs-to-bq: classpath:pipeline-gcs-to-bq-template.yml
      gcs-to-gcs: classpath:pipeline-gcs-to-gcs-template.yml
      warehouse-to-gcs-to-bq: classpath:pipeline-warehouse-to-gcs-to-bq-template.yml
      bq-to-gcs: classpath:pipeline-bq-to-gcs-template.yml
    # Restrict execution to a single source handler when multiple are configured (postgres, oracle, mysql, gcs).
    # Set to the allowed type (e.g. postgres, oracle, or mysql); execute requests with a different source will be rejected.
    # Leave empty for no restriction (any registered handler allowed).
    # Example: expected-handler: postgres
    expected-handler:

# ============================================================================
# Spring AI — Vertex AI Gemini (auto-configuration)
# These keys are read by spring-ai-vertex-ai-gemini-spring-boot-starter.
# Profile-specific overrides live in application-{profile}.yml.
# ============================================================================
spring:
  ai:
    vertex:
      ai:
        gemini:
          project-id: ${VERTEX_PROJECT_ID:your-gcp-project-id}
          location:   ${VERTEX_LOCATION:us-central1}
          chat:
            options:
              model:             ${AI_CHAT_MODEL:gemini-2.0-flash-001}
              temperature:       ${AI_TEMPERATURE:0.3}
              top-p:             ${AI_TOP_P:0.95}
              max-output-tokens: ${AI_MAX_TOKENS:8192}
              candidate-count:   1
          embedding:
            options:
              model:                  ${AI_EMBEDDING_MODEL:text-embedding-004}
              output-dimensionality:  768
