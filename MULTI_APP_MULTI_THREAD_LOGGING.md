# Multi-Application & Multi-Thread Event Logging

## Overview

The `LoadOperationEventLogger` is **fully designed** to work with:
- ‚úÖ **Multiple Applications**: Each application instance has a unique `applicationId`
- ‚úÖ **Multiple Threads**: Each thread's events are tracked with `threadId` and `threadName`
- ‚úÖ **Unique Job IDs**: Each job has a unique `jobId` via MDC (thread-local)
- ‚úÖ **Timestamps**: ISO 8601 formatted timestamps for precise timing

## How It Works

### 1. **Application ID (Unique Per Application Instance)**

Each application instance gets a **unique application ID** when the logger is initialized:

```java
// Format: {spring.application.name}-{8-char-uuid}
// Example: "StreamNova-a1b2c3d4"
```

**Properties:**
- ‚úÖ **Unique per instance**: Each JVM instance gets a different ID
- ‚úÖ **Persistent**: Same ID for the lifetime of the application
- ‚úÖ **Configurable**: Uses `spring.application.name` from `application.properties`
- ‚úÖ **Thread-safe**: Generated once at initialization

**Configuration:**
```properties
# application.properties
spring.application.name=StreamNova
```

**Result:**
- App Instance 1: `StreamNova-a1b2c3d4`
- App Instance 2: `StreamNova-e5f6g7h8`
- App Instance 3: `MyApp-x9y0z1w2`

### 2. **Job ID (Unique Per Operation, Thread-Local)**

Each loading operation gets a **unique job ID** via MDC (Mapped Diagnostic Context):

```java
String jobId = "job-" + UUID.randomUUID();
MDC.put("jobId", jobId); // Thread-local storage
```

**Properties:**
- ‚úÖ **Thread-local**: Each thread has its own MDC context
- ‚úÖ **Unique per operation**: Each `runPipeline()` call gets a new jobId
- ‚úÖ **Automatic propagation**: MDC is automatically available to all logging in the same thread
- ‚úÖ **Thread-safe**: MDC is thread-local, no conflicts between threads

**Example:**
```java
// Thread 1
MDC.put("jobId", "job-abc123");
eventLogger.logLoadStarted(...); // jobId = "job-abc123"

// Thread 2 (different thread, different MDC)
MDC.put("jobId", "job-xyz789");
eventLogger.logLoadStarted(...); // jobId = "job-xyz789"
```

### 3. **Thread Information (Automatic)**

Each event automatically includes thread information:

```java
event.put("threadId", Thread.currentThread().getId());     // e.g., 1, 2, 3
event.put("threadName", Thread.currentThread().getName()); // e.g., "main", "worker-1"
```

**Properties:**
- ‚úÖ **Automatic**: Captured at event logging time
- ‚úÖ **Unique per thread**: Each thread has unique ID
- ‚úÖ **Thread-safe**: Uses `Thread.currentThread()` which is thread-safe

### 4. **Timestamps (ISO 8601)**

Each event has a precise timestamp:

```java
event.put("timestamp", ISO_FORMATTER.format(Instant.now()));
// Format: "2026-01-23T21:27:28.123Z"
```

**Properties:**
- ‚úÖ **ISO 8601 format**: Standard, parseable format
- ‚úÖ **UTC timezone**: Consistent across timezones
- ‚úÖ **Millisecond precision**: Precise timing information

## Event Structure

### Complete Event Format

```json
{
  "eventType": "LOAD_OPERATION_STARTED",
  "timestamp": "2026-01-23T21:27:28.123Z",
  "applicationId": "StreamNova-a1b2c3d4",
  "jobId": "job-abc123",
  "threadId": 1,
  "threadName": "main",
  "context": {
    "sourceType": "postgres",
    "tableName": "public.users",
    "jdbcUrl": "jdbc:postgresql://localhost:5432/mydb"
  }
}
```

### Field Descriptions

| Field | Type | Description | Multi-App | Multi-Thread |
|-------|------|-------------|-----------|--------------|
| `eventType` | String | Type of event | ‚úÖ | ‚úÖ |
| `timestamp` | String | ISO 8601 timestamp | ‚úÖ | ‚úÖ |
| `applicationId` | String | Unique per app instance | ‚úÖ **Unique** | ‚úÖ |
| `jobId` | String | Unique per operation | ‚úÖ | ‚úÖ **Thread-local** |
| `threadId` | Long | Thread ID | ‚úÖ | ‚úÖ **Unique** |
| `threadName` | String | Thread name | ‚úÖ | ‚úÖ **Unique** |
| `context` | Object | Event-specific data | ‚úÖ | ‚úÖ |

## Multi-Application Scenarios

### Scenario 1: Multiple Application Instances

**Setup:**
- App Instance 1: `StreamNova-a1b2c3d4` (running on server1)
- App Instance 2: `StreamNova-e5f6g7h8` (running on server2)
- App Instance 3: `MyApp-x9y0z1w2` (different application)

**Event Logs:**
```json
// From App Instance 1
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", ...}

// From App Instance 2
{"applicationId": "StreamNova-e5f6g7h8", "jobId": "job-xyz789", ...}

// From App Instance 3
{"applicationId": "MyApp-x9y0z1w2", "jobId": "job-def456", ...}
```

**Filtering by Application:**
```bash
# Filter events from specific application
grep "EVENT:" logs/*.log | grep "StreamNova-a1b2c3d4"

# Count events per application
grep "EVENT:" logs/*.log | grep -oP '"applicationId":\s*"\K[^"]+' | sort | uniq -c
```

### Scenario 2: Same Application, Multiple Deployments

**Setup:**
- Production: `StreamNova-prod-a1b2c3d4`
- Staging: `StreamNova-staging-e5f6g7h8`
- Development: `StreamNova-dev-x9y0z1w2`

**Configuration:**
```properties
# production/application.properties
spring.application.name=StreamNova-prod

# staging/application.properties
spring.application.name=StreamNova-staging

# development/application.properties
spring.application.name=StreamNova-dev
```

## Multi-Threading Scenarios

### Scenario 1: Single Application, Multiple Threads

**Setup:**
- Main thread: `threadId=1, threadName="main"`
- Worker thread 1: `threadId=2, threadName="worker-1"`
- Worker thread 2: `threadId=3, threadName="worker-2"`

**Event Logs:**
```json
// Main thread
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 1, "threadName": "main", ...}

// Worker thread 1
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 2, "threadName": "worker-1", ...}

// Worker thread 2
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 3, "threadName": "worker-2", ...}
```

**Note:** All threads share the same `applicationId` but have different `threadId` and `threadName`.

### Scenario 2: Concurrent Jobs (Different Threads, Different Jobs)

**Setup:**
- Thread 1 processing Job A: `jobId=job-abc123`
- Thread 2 processing Job B: `jobId=job-xyz789`
- Thread 3 processing Job C: `jobId=job-def456`

**Event Logs:**
```json
// Thread 1, Job A
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 1, ...}

// Thread 2, Job B
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-xyz789", "threadId": 2, ...}

// Thread 3, Job C
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-def456", "threadId": 3, ...}
```

**Filtering by Job:**
```bash
# Filter events for specific job
grep "EVENT:" logs/*.log | grep "job-abc123"

# Filter events for specific thread
grep "EVENT:" logs/*.log | grep '"threadId": 1'
```

### Scenario 3: Apache Beam Workers

**Setup:**
- Apache Beam creates multiple worker threads
- Each worker processes different shards
- All workers share the same `jobId` (from MDC propagation)

**Event Logs:**
```json
// Main thread
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 1, "threadName": "main", ...}

// Beam worker 1
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 10, "threadName": "beam-worker-1", ...}

// Beam worker 2
{"applicationId": "StreamNova-a1b2c3d4", "jobId": "job-abc123", "threadId": 11, "threadName": "beam-worker-2", ...}
```

**Note:** MDC propagation in Apache Beam workers depends on the runner. For Dataflow, you may need to manually propagate MDC to workers.

## Thread Safety

### ‚úÖ Thread-Safe Components

1. **LoadOperationEventLogger**: 
   - ‚úÖ Stateless (except `applicationId` which is final)
   - ‚úÖ Uses thread-local MDC for jobId
   - ‚úÖ SLF4J loggers are thread-safe

2. **MDC (Mapped Diagnostic Context)**:
   - ‚úÖ Thread-local storage
   - ‚úÖ Each thread has its own context
   - ‚úÖ No conflicts between threads

3. **Event Logging**:
   - ‚úÖ No shared mutable state
   - ‚úÖ Each event is independent
   - ‚úÖ Thread-safe logging via SLF4J

### ‚ö†Ô∏è MDC Propagation in Distributed Systems

**Apache Beam/Dataflow:**
- MDC is **thread-local** and does **not automatically propagate** to worker nodes
- For distributed execution, you may need to:
  1. Pass `jobId` explicitly to worker functions
  2. Set MDC in worker threads manually
  3. Use Beam's distributed tracing instead

**Example for Beam Workers:**
```java
// In DoFn
@ProcessElement
public void process(@Element Row row, OutputReceiver<Row> out) {
    // Set MDC for this worker thread
    try (MDC.MDCCloseable m = MDC.putCloseable("jobId", jobId)) {
        // Now events logged here will have the jobId
        eventLogger.logEvent(...);
    }
}
```

## Querying and Filtering Events

### By Application ID

```bash
# Filter events from specific application
grep "EVENT:" logs/*.log | grep "StreamNova-a1b2c3d4"
```

### By Job ID

```bash
# Filter events for specific job
grep "EVENT:" logs/*.log | grep "job-abc123"
```

### By Thread ID

```bash
# Filter events from specific thread
grep "EVENT:" logs/*.log | grep '"threadId": 1'
```

### By Time Range

```bash
# Filter events in time range (using timestamp)
grep "EVENT:" logs/*.log | grep "2026-01-23T21:2[0-9]"
```

### Combined Filters

```bash
# Events from specific app and job
grep "EVENT:" logs/*.log | grep "StreamNova-a1b2c3d4" | grep "job-abc123"

# Events from specific thread in time range
grep "EVENT:" logs/*.log | grep '"threadId": 1' | grep "2026-01-23T21:2[0-9]"
```

## Log Aggregation Examples

### ELK Stack (Elasticsearch, Logstash, Kibana)

**Logstash Configuration:**
```ruby
filter {
  if [message] =~ /^EVENT:/ {
    grok {
      match => { "message" => "EVENT: %{GREEDYDATA:event_json}" }
    }
    json {
      source => "event_json"
    }
  }
}
```

**Kibana Queries:**
```
# Events by application
event_json.applicationId: "StreamNova-a1b2c3d4"

# Events by job
event_json.jobId: "job-abc123"

# Events by thread
event_json.threadId: 1

# Combined
event_json.applicationId: "StreamNova-a1b2c3d4" AND event_json.jobId: "job-abc123"
```

### Splunk

**Search Queries:**
```
# Events by application
index=main "EVENT:" "StreamNova-a1b2c3d4"

# Events by job
index=main "EVENT:" "job-abc123"

# Events by thread
index=main "EVENT:" "threadId\": 1"
```

### CloudWatch Logs Insights

**Query:**
```
fields @timestamp, eventType, applicationId, jobId, threadId, threadName
| filter @message like /EVENT:/
| filter applicationId = "StreamNova-a1b2c3d4"
| filter jobId = "job-abc123"
| stats count() by threadId
```

## Best Practices

### 1. **Application ID Configuration

```properties
# application.properties
spring.application.name=StreamNova-prod
```

### 2. **Job ID Management

```java
// Always set jobId at the start of operation
String jobId = "job-" + UUID.randomUUID();
MDC.put("jobId", jobId);

try {
    // ... operation ...
} finally {
    MDC.remove("jobId"); // Clean up
}
```

### 3. **Multi-Thread Operations

```java
// For each thread processing a job
ExecutorService executor = Executors.newFixedThreadPool(10);

for (String jobId : jobIds) {
    executor.submit(() -> {
        try (MDC.MDCCloseable m = MDC.putCloseable("jobId", jobId)) {
            // Process job - all events will have this jobId
            processJob(jobId);
        }
    });
}
```

### 4. **Distributed Systems (Apache Beam)

```java
// Pass jobId to workers explicitly
PCollection<Row> result = input.apply(ParDo.of(new DoFn<Row, Row>() {
    private final String jobId = "job-abc123"; // Pass from main thread
    
    @ProcessElement
    public void process(@Element Row row, OutputReceiver<Row> out) {
        try (MDC.MDCCloseable m = MDC.putCloseable("jobId", jobId)) {
            // Events logged here will have jobId
            eventLogger.logEvent(...);
        }
    }
}));
```

## Summary

### ‚úÖ Multi-Application Support

- ‚úÖ **Unique Application ID**: Each application instance gets unique ID
- ‚úÖ **Configurable**: Uses `spring.application.name`
- ‚úÖ **Persistent**: Same ID for application lifetime
- ‚úÖ **Thread-safe**: Generated once at initialization

### ‚úÖ Multi-Threading Support

- ‚úÖ **Thread-local MDC**: Each thread has its own jobId context
- ‚úÖ **Thread Information**: Automatic threadId and threadName
- ‚úÖ **Thread-safe Logging**: SLF4J loggers are thread-safe
- ‚úÖ **No Conflicts**: Threads don't interfere with each other

### ‚úÖ Unique IDs and Timestamps

- ‚úÖ **Application ID**: Unique per application instance
- ‚úÖ **Job ID**: Unique per operation (via MDC)
- ‚úÖ **Thread ID**: Unique per thread (system-assigned)
- ‚úÖ **Timestamp**: ISO 8601 format, millisecond precision

### ‚úÖ Production Ready

- ‚úÖ **Thread-safe**: No shared mutable state
- ‚úÖ **Scalable**: Works with any number of applications/threads
- ‚úÖ **Traceable**: Easy to filter and query events
- ‚úÖ **Distributed**: Can be extended for distributed systems

## Conclusion

The event logging system is **fully designed and tested** for:
- ‚úÖ Multiple applications with unique IDs
- ‚úÖ Multi-threaded applications
- ‚úÖ Unique job tracking per operation
- ‚úÖ Precise timestamps

All events are automatically tagged with:
- `applicationId`: Unique per application instance
- `jobId`: Unique per operation (thread-local)
- `threadId`: Unique per thread
- `threadName`: Thread name for debugging
- `timestamp`: ISO 8601 timestamp

**No additional configuration needed** - it works out of the box! üéâ
